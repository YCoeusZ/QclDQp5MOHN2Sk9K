{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "621ef0e6",
   "metadata": {},
   "source": [
    "# Xgboost\n",
    "\n",
    "This document is dedicated to the testing of xgboost models. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "c98205b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_selection import f_classif, mutual_info_classif\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_selection import RFE\n",
    "import importlib\n",
    "import sys \n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "sys.path.append(\"../\")\n",
    "\n",
    "from proj_mod import visualization, data_processing, training \n",
    "importlib.reload(visualization);\n",
    "importlib.reload(data_processing);\n",
    "importlib.reload(training); \n",
    "\n",
    "from joblib import dump, load\n",
    "import cloudpickle as cp\n",
    "\n",
    "seed=420"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "dbc0c791",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv(\"../data/raw.csv\")\n",
    "df[\"y\"]=df[\"y\"].map({\"no\": 0, \"yes\": 1})\n",
    "features=df.columns[:-1]\n",
    "df_feat=df[features]\n",
    "# df_feat[\"month_num\"]=df_feat[\"month\"].map({\"jan\":1, \"feb\":2, \"mar\":3, \"apr\":4, \"may\":5, \"jun\":6, \"jul\":7, \"aug\":8, \"sep\":9, \"oct\":10, \"nov\":11, \"dec\":12}).to_numpy().astype(int)\n",
    "# df_feat[\"day_of_year\"]=data_processing.day_of_non_leap_np(month_arr=df_feat[\"month_num\"].to_numpy(), day_arr=df_feat[\"day\"].to_numpy()).astype(int)\n",
    "df_tar=df[[\"y\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f89487b7",
   "metadata": {},
   "source": [
    "## We first do it for the whole feature set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "5ee91496",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_base=XGBClassifier(\n",
    "    device=\"cuda\", \n",
    "    tree_method=\"hist\", \n",
    "    eval_metric=\"aucpr\",\n",
    "    random_state=seed\n",
    ")\n",
    "\n",
    "pipe= Pipeline(\n",
    "    [\n",
    "        (\"data_transform\", data_processing.data_transform()), \n",
    "        (\"data_select\", data_processing.data_selector(cut=0.98, how=\"mi score\", mi_n_jobs=1)), \n",
    "        (\"RFE\", RFE(estimator=xgb_base, step=0.1)), \n",
    "        (\"XGB\", XGBClassifier(\n",
    "            device=\"cuda\", \n",
    "            tree_method=\"hist\", \n",
    "            eval_metric=\"aucpr\", \n",
    "            random_state=seed\n",
    "        ))\n",
    "    ]\n",
    ")\n",
    "\n",
    "param_dict={\n",
    "    \"XGB__max_depth\": [3, 4, 5, 6],\n",
    "    \"XGB__min_child_weight\": [1, 2, 4, 6],\n",
    "    \"XGB__subsample\": np.linspace(0.7, 1.0, 4),\n",
    "    \"XGB__colsample_bytree\": np.linspace(0.7, 1.0, 4),\n",
    "    \"XGB__learning_rate\": np.geomspace(1e-2, 0.2, 5),\n",
    "    \"XGB__n_estimators\": [600, 1000, 1400],  \n",
    "    \"XGB__reg_lambda\": np.geomspace(1e-2, 100, 6),\n",
    "    \"XGB__reg_alpha\": np.geomspace(1e-3, 10, 6),\n",
    "    \"XGB__gamma\": np.linspace(0.0, 5.0, 6),\n",
    "    \"XGB__scale_pos_weight\": None # The model_eval will set this \n",
    "}\n",
    "\n",
    "SKF=StratifiedKFold(n_splits=5, shuffle=True, random_state=seed)\n",
    "outer_split=list(SKF.split(X=df_feat, y=df_tar))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "17b8dbf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_eval=training.model_eval(search_method=\"Random\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76889d85",
   "metadata": {},
   "source": [
    "This needs 90 mins if gpu is not used. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "521ddc29",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_eval.eval(df_feat=df_feat, df_tar=df_tar, pipe=pipe, outer_cv=outer_split, param_dict=param_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c96767f",
   "metadata": {},
   "outputs": [],
   "source": [
    "fitted_dict=model_eval.fitted_dict_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c379ebc",
   "metadata": {},
   "source": [
    "Below saves the fitted models (whole pipes). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c246dea3",
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in fitted_dict.keys(): \n",
    "    with open(f\"../data/fitted/xgboost/fitted_pipe_xgboost_{key}_run_1.pkl\", \"wb\") as f: \n",
    "        cp.dump(fitted_dict[key][0],f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59934220",
   "metadata": {},
   "source": [
    "Below saves the dictionary. This saves literally all data according to the training, prefer this. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "481f5195",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../data/fitted/xgboost/fitted_dict_run1.pkl\", \"wb\") as f: \n",
    "    cp.dump(fitted_dict, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb909e25",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Even better, use this instead. \n",
    "model_eval.save_dict(save_path=\"../data/fitted/xgboost/fitted_dict_run1.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dc54a9a",
   "metadata": {},
   "source": [
    "Below loads the dictionary. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "764bb9d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading completed. \n"
     ]
    }
   ],
   "source": [
    "model_eval.load_dict(load_path=\"../data/fitted/xgboost/fitted_dict_run1.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1b807f8",
   "metadata": {},
   "source": [
    "The following produces prediction with different threshold cutoffs. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "ad4073db",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_eval.pred_by_threshold()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "cfc8a248",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Fold 1': array([[1., 1., 1., ..., 1., 1., 1.],\n",
       "        [0., 1., 1., ..., 1., 1., 1.],\n",
       "        [0., 0., 1., ..., 1., 1., 1.],\n",
       "        ...,\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.]]),\n",
       " 'Fold 2': array([[1., 1., 1., ..., 1., 1., 1.],\n",
       "        [0., 0., 1., ..., 1., 1., 1.],\n",
       "        [0., 0., 0., ..., 1., 1., 1.],\n",
       "        ...,\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.]]),\n",
       " 'Fold 3': array([[1., 1., 1., ..., 1., 1., 1.],\n",
       "        [1., 0., 0., ..., 1., 1., 1.],\n",
       "        [1., 0., 0., ..., 1., 1., 1.],\n",
       "        ...,\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.]]),\n",
       " 'Fold 4': array([[1., 1., 1., ..., 1., 1., 1.],\n",
       "        [0., 0., 1., ..., 1., 1., 1.],\n",
       "        [0., 0., 1., ..., 1., 1., 1.],\n",
       "        ...,\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.]]),\n",
       " 'Fold 5': array([[1., 1., 1., ..., 1., 1., 1.],\n",
       "        [0., 0., 0., ..., 1., 1., 1.],\n",
       "        [0., 0., 0., ..., 1., 1., 1.],\n",
       "        ...,\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.]])}"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_eval.pred_by_threshold_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d2c0ed4",
   "metadata": {},
   "source": [
    "The following creates the confusion matrix data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "2ed24d1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_eval.confusion_data_by_threshold(y=df_tar, outer_cv=outer_split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "0af15195",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Fold 1': {'TP': array([579, 576, 576, 575, 575, 575, 574, 574, 573, 571, 571, 571, 570,\n",
       "         570, 569, 568, 567, 567, 567, 567, 562, 559, 558, 558, 558, 558,\n",
       "         557, 553, 552, 552, 551, 550, 550, 548, 545, 545, 544, 544, 543,\n",
       "         541, 541, 540, 540, 539, 538, 537, 535, 533, 531, 529, 527, 524,\n",
       "         523, 521, 520, 520, 519, 514, 513, 511, 506, 504, 501, 500, 499,\n",
       "         496, 492, 487, 485, 482, 479, 477, 468, 466, 462, 461, 457, 449,\n",
       "         444, 433, 426, 424, 413, 405, 399, 382, 369, 359, 345, 330, 305,\n",
       "         282, 254, 216, 174, 117,  76,  36,  11,   2,   0]),\n",
       "  'FP': array([7421, 4563, 3617, 3132, 2817, 2585, 2427, 2312, 2198, 2109, 2046,\n",
       "         1970, 1923, 1872, 1833, 1782, 1738, 1697, 1652, 1625, 1583, 1550,\n",
       "         1504, 1487, 1454, 1430, 1399, 1369, 1344, 1315, 1290, 1273, 1245,\n",
       "         1226, 1202, 1185, 1165, 1145, 1119, 1096, 1075, 1056, 1042, 1024,\n",
       "         1010,  984,  964,  951,  942,  929,  916,  903,  884,  870,  854,\n",
       "          836,  825,  810,  792,  779,  757,  742,  729,  725,  705,  690,\n",
       "          673,  652,  642,  624,  605,  591,  575,  560,  545,  525,  509,\n",
       "          497,  479,  462,  447,  422,  409,  392,  378,  350,  329,  305,\n",
       "          273,  251,  221,  199,  174,  140,   97,   62,   31,    9,    1,\n",
       "            0,    0]),\n",
       "  'TN': array([   0, 2858, 3804, 4289, 4604, 4836, 4994, 5109, 5223, 5312, 5375,\n",
       "         5451, 5498, 5549, 5588, 5639, 5683, 5724, 5769, 5796, 5838, 5871,\n",
       "         5917, 5934, 5967, 5991, 6022, 6052, 6077, 6106, 6131, 6148, 6176,\n",
       "         6195, 6219, 6236, 6256, 6276, 6302, 6325, 6346, 6365, 6379, 6397,\n",
       "         6411, 6437, 6457, 6470, 6479, 6492, 6505, 6518, 6537, 6551, 6567,\n",
       "         6585, 6596, 6611, 6629, 6642, 6664, 6679, 6692, 6696, 6716, 6731,\n",
       "         6748, 6769, 6779, 6797, 6816, 6830, 6846, 6861, 6876, 6896, 6912,\n",
       "         6924, 6942, 6959, 6974, 6999, 7012, 7029, 7043, 7071, 7092, 7116,\n",
       "         7148, 7170, 7200, 7222, 7247, 7281, 7324, 7359, 7390, 7412, 7420,\n",
       "         7421, 7421]),\n",
       "  'FN': array([  0,   3,   3,   4,   4,   4,   5,   5,   6,   8,   8,   8,   9,\n",
       "           9,  10,  11,  12,  12,  12,  12,  17,  20,  21,  21,  21,  21,\n",
       "          22,  26,  27,  27,  28,  29,  29,  31,  34,  34,  35,  35,  36,\n",
       "          38,  38,  39,  39,  40,  41,  42,  44,  46,  48,  50,  52,  55,\n",
       "          56,  58,  59,  59,  60,  65,  66,  68,  73,  75,  78,  79,  80,\n",
       "          83,  87,  92,  94,  97, 100, 102, 111, 113, 117, 118, 122, 130,\n",
       "         135, 146, 153, 155, 166, 174, 180, 197, 210, 220, 234, 249, 274,\n",
       "         297, 325, 363, 405, 462, 503, 543, 568, 577, 579])},\n",
       " 'Fold 2': {'TP': array([579, 579, 579, 576, 574, 573, 573, 572, 571, 569, 568, 567, 566,\n",
       "         565, 565, 565, 565, 565, 565, 564, 564, 564, 563, 562, 562, 560,\n",
       "         558, 557, 557, 556, 555, 555, 555, 554, 552, 551, 551, 550, 548,\n",
       "         545, 542, 541, 541, 540, 538, 538, 537, 536, 535, 534, 532, 532,\n",
       "         529, 527, 527, 524, 521, 520, 516, 515, 514, 505, 505, 502, 498,\n",
       "         494, 491, 482, 481, 478, 476, 473, 466, 461, 455, 450, 445, 440,\n",
       "         428, 419, 410, 402, 391, 379, 371, 360, 346, 335, 321, 304, 286,\n",
       "         260, 231, 201, 167, 127,  76,  38,  16,   0,   0]),\n",
       "  'FP': array([7421, 4989, 3792, 3243, 2887, 2641, 2458, 2295, 2199, 2114, 2037,\n",
       "         1971, 1906, 1846, 1811, 1770, 1724, 1688, 1642, 1595, 1558, 1523,\n",
       "         1488, 1454, 1419, 1386, 1354, 1328, 1311, 1290, 1268, 1243, 1221,\n",
       "         1209, 1186, 1162, 1137, 1119, 1095, 1084, 1063, 1052, 1037, 1016,\n",
       "         1003,  982,  968,  951,  936,  924,  912,  896,  882,  864,  847,\n",
       "          833,  819,  800,  788,  768,  758,  735,  720,  701,  688,  669,\n",
       "          655,  643,  631,  611,  596,  584,  562,  537,  516,  493,  471,\n",
       "          453,  436,  411,  391,  373,  354,  338,  320,  303,  288,  268,\n",
       "          253,  227,  198,  173,  146,  112,   90,   61,   27,   11,    4,\n",
       "            0,    0]),\n",
       "  'TN': array([   0, 2432, 3629, 4178, 4534, 4780, 4963, 5126, 5222, 5307, 5384,\n",
       "         5450, 5515, 5575, 5610, 5651, 5697, 5733, 5779, 5826, 5863, 5898,\n",
       "         5933, 5967, 6002, 6035, 6067, 6093, 6110, 6131, 6153, 6178, 6200,\n",
       "         6212, 6235, 6259, 6284, 6302, 6326, 6337, 6358, 6369, 6384, 6405,\n",
       "         6418, 6439, 6453, 6470, 6485, 6497, 6509, 6525, 6539, 6557, 6574,\n",
       "         6588, 6602, 6621, 6633, 6653, 6663, 6686, 6701, 6720, 6733, 6752,\n",
       "         6766, 6778, 6790, 6810, 6825, 6837, 6859, 6884, 6905, 6928, 6950,\n",
       "         6968, 6985, 7010, 7030, 7048, 7067, 7083, 7101, 7118, 7133, 7153,\n",
       "         7168, 7194, 7223, 7248, 7275, 7309, 7331, 7360, 7394, 7410, 7417,\n",
       "         7421, 7421]),\n",
       "  'FN': array([  0,   0,   0,   3,   5,   6,   6,   7,   8,  10,  11,  12,  13,\n",
       "          14,  14,  14,  14,  14,  14,  15,  15,  15,  16,  17,  17,  19,\n",
       "          21,  22,  22,  23,  24,  24,  24,  25,  27,  28,  28,  29,  31,\n",
       "          34,  37,  38,  38,  39,  41,  41,  42,  43,  44,  45,  47,  47,\n",
       "          50,  52,  52,  55,  58,  59,  63,  64,  65,  74,  74,  77,  81,\n",
       "          85,  88,  97,  98, 101, 103, 106, 113, 118, 124, 129, 134, 139,\n",
       "         151, 160, 169, 177, 188, 200, 208, 219, 233, 244, 258, 275, 293,\n",
       "         319, 348, 378, 412, 452, 503, 541, 563, 579, 579])},\n",
       " 'Fold 3': {'TP': array([579, 578, 578, 578, 577, 575, 574, 572, 572, 572, 571, 570, 569,\n",
       "         569, 568, 568, 568, 566, 563, 563, 563, 563, 563, 563, 562, 561,\n",
       "         560, 559, 557, 555, 553, 552, 551, 551, 551, 551, 551, 550, 550,\n",
       "         550, 550, 549, 549, 544, 542, 540, 540, 538, 537, 537, 535, 534,\n",
       "         530, 527, 525, 523, 523, 520, 519, 516, 515, 513, 512, 506, 504,\n",
       "         501, 499, 496, 490, 486, 485, 481, 477, 470, 464, 462, 460, 458,\n",
       "         453, 441, 431, 424, 419, 407, 396, 385, 371, 360, 345, 328, 299,\n",
       "         275, 251, 213, 178, 129,  78,  32,   9,   0,   0]),\n",
       "  'FP': array([7421, 4800, 3751, 3227, 2889, 2661, 2494, 2355, 2242, 2146, 2089,\n",
       "         2008, 1948, 1885, 1827, 1778, 1737, 1696, 1647, 1625, 1582, 1551,\n",
       "         1507, 1478, 1446, 1417, 1381, 1350, 1332, 1306, 1281, 1249, 1229,\n",
       "         1205, 1184, 1166, 1144, 1124, 1109, 1087, 1067, 1053, 1036, 1022,\n",
       "         1004,  981,  972,  959,  950,  931,  922,  910,  894,  883,  867,\n",
       "          854,  845,  831,  817,  807,  796,  782,  761,  746,  730,  722,\n",
       "          701,  678,  661,  647,  630,  613,  592,  575,  553,  537,  517,\n",
       "          494,  475,  455,  435,  408,  389,  374,  354,  330,  305,  285,\n",
       "          256,  224,  193,  163,  146,  116,   88,   57,   36,   15,    4,\n",
       "            0,    0]),\n",
       "  'TN': array([   0, 2621, 3670, 4194, 4532, 4760, 4927, 5066, 5179, 5275, 5332,\n",
       "         5413, 5473, 5536, 5594, 5643, 5684, 5725, 5774, 5796, 5839, 5870,\n",
       "         5914, 5943, 5975, 6004, 6040, 6071, 6089, 6115, 6140, 6172, 6192,\n",
       "         6216, 6237, 6255, 6277, 6297, 6312, 6334, 6354, 6368, 6385, 6399,\n",
       "         6417, 6440, 6449, 6462, 6471, 6490, 6499, 6511, 6527, 6538, 6554,\n",
       "         6567, 6576, 6590, 6604, 6614, 6625, 6639, 6660, 6675, 6691, 6699,\n",
       "         6720, 6743, 6760, 6774, 6791, 6808, 6829, 6846, 6868, 6884, 6904,\n",
       "         6927, 6946, 6966, 6986, 7013, 7032, 7047, 7067, 7091, 7116, 7136,\n",
       "         7165, 7197, 7228, 7258, 7275, 7305, 7333, 7364, 7385, 7406, 7417,\n",
       "         7421, 7421]),\n",
       "  'FN': array([  0,   1,   1,   1,   2,   4,   5,   7,   7,   7,   8,   9,  10,\n",
       "          10,  11,  11,  11,  13,  16,  16,  16,  16,  16,  16,  17,  18,\n",
       "          19,  20,  22,  24,  26,  27,  28,  28,  28,  28,  28,  29,  29,\n",
       "          29,  29,  30,  30,  35,  37,  39,  39,  41,  42,  42,  44,  45,\n",
       "          49,  52,  54,  56,  56,  59,  60,  63,  64,  66,  67,  73,  75,\n",
       "          78,  80,  83,  89,  93,  94,  98, 102, 109, 115, 117, 119, 121,\n",
       "         126, 138, 148, 155, 160, 172, 183, 194, 208, 219, 234, 251, 280,\n",
       "         304, 328, 366, 401, 450, 501, 547, 570, 579, 579])},\n",
       " 'Fold 4': {'TP': array([579, 579, 577, 577, 576, 576, 576, 575, 574, 574, 574, 574, 574,\n",
       "         570, 568, 568, 568, 566, 565, 565, 563, 562, 562, 561, 560, 557,\n",
       "         556, 552, 551, 550, 550, 549, 548, 545, 542, 539, 536, 533, 531,\n",
       "         529, 527, 524, 524, 524, 522, 521, 519, 517, 515, 514, 512, 512,\n",
       "         509, 508, 506, 505, 501, 500, 497, 497, 493, 489, 489, 487, 485,\n",
       "         482, 472, 467, 464, 460, 453, 448, 439, 431, 427, 419, 413, 403,\n",
       "         396, 386, 379, 367, 357, 343, 328, 313, 296, 275, 257, 234, 200,\n",
       "         168, 147, 101,  71,  51,  31,  12,   4,   1,   0]),\n",
       "  'FP': array([7421, 4577, 3418, 2933, 2663, 2484, 2344, 2236, 2126, 2025, 1938,\n",
       "         1878, 1824, 1761, 1704, 1650, 1609, 1569, 1522, 1486, 1447, 1398,\n",
       "         1362, 1328, 1299, 1268, 1244, 1229, 1215, 1180, 1166, 1143, 1125,\n",
       "         1108, 1097, 1085, 1059, 1045, 1024, 1009,  992,  981,  959,  938,\n",
       "          918,  899,  886,  864,  851,  838,  823,  804,  788,  779,  760,\n",
       "          747,  738,  725,  714,  691,  681,  663,  647,  627,  611,  599,\n",
       "          574,  557,  542,  528,  513,  496,  471,  446,  431,  413,  396,\n",
       "          380,  365,  342,  328,  304,  282,  264,  243,  227,  204,  187,\n",
       "          154,  130,  108,   84,   67,   50,   36,   25,   13,    2,    0,\n",
       "            0,    0]),\n",
       "  'TN': array([   0, 2844, 4003, 4488, 4758, 4937, 5077, 5185, 5295, 5396, 5483,\n",
       "         5543, 5597, 5660, 5717, 5771, 5812, 5852, 5899, 5935, 5974, 6023,\n",
       "         6059, 6093, 6122, 6153, 6177, 6192, 6206, 6241, 6255, 6278, 6296,\n",
       "         6313, 6324, 6336, 6362, 6376, 6397, 6412, 6429, 6440, 6462, 6483,\n",
       "         6503, 6522, 6535, 6557, 6570, 6583, 6598, 6617, 6633, 6642, 6661,\n",
       "         6674, 6683, 6696, 6707, 6730, 6740, 6758, 6774, 6794, 6810, 6822,\n",
       "         6847, 6864, 6879, 6893, 6908, 6925, 6950, 6975, 6990, 7008, 7025,\n",
       "         7041, 7056, 7079, 7093, 7117, 7139, 7157, 7178, 7194, 7217, 7234,\n",
       "         7267, 7291, 7313, 7337, 7354, 7371, 7385, 7396, 7408, 7419, 7421,\n",
       "         7421, 7421]),\n",
       "  'FN': array([  0,   0,   2,   2,   3,   3,   3,   4,   5,   5,   5,   5,   5,\n",
       "           9,  11,  11,  11,  13,  14,  14,  16,  17,  17,  18,  19,  22,\n",
       "          23,  27,  28,  29,  29,  30,  31,  34,  37,  40,  43,  46,  48,\n",
       "          50,  52,  55,  55,  55,  57,  58,  60,  62,  64,  65,  67,  67,\n",
       "          70,  71,  73,  74,  78,  79,  82,  82,  86,  90,  90,  92,  94,\n",
       "          97, 107, 112, 115, 119, 126, 131, 140, 148, 152, 160, 166, 176,\n",
       "         183, 193, 200, 212, 222, 236, 251, 266, 283, 304, 322, 345, 379,\n",
       "         411, 432, 478, 508, 528, 548, 567, 575, 578, 579])},\n",
       " 'Fold 5': {'TP': array([580, 578, 576, 574, 572, 572, 571, 569, 567, 565, 564, 563, 561,\n",
       "         556, 556, 555, 553, 552, 547, 543, 542, 542, 542, 539, 534, 533,\n",
       "         529, 527, 525, 524, 522, 519, 518, 516, 513, 513, 513, 510, 510,\n",
       "         510, 508, 504, 504, 502, 502, 500, 500, 499, 497, 497, 496, 492,\n",
       "         490, 488, 486, 482, 479, 476, 473, 470, 467, 463, 459, 458, 456,\n",
       "         455, 452, 446, 442, 433, 426, 422, 419, 413, 405, 398, 393, 384,\n",
       "         372, 359, 354, 349, 341, 333, 314, 292, 275, 255, 239, 222, 192,\n",
       "         173, 149, 125,  96,  65,  42,  23,   1,   0,   0]),\n",
       "  'FP': array([7420, 3337, 2593, 2283, 2084, 1953, 1857, 1775, 1679, 1593, 1534,\n",
       "         1484, 1440, 1395, 1357, 1322, 1282, 1252, 1208, 1173, 1150, 1123,\n",
       "         1104, 1081, 1056, 1037, 1014,  995,  980,  967,  952,  936,  916,\n",
       "          904,  888,  876,  864,  849,  840,  827,  813,  803,  791,  785,\n",
       "          770,  757,  748,  729,  720,  704,  699,  684,  674,  661,  656,\n",
       "          642,  627,  613,  601,  589,  576,  563,  546,  530,  515,  499,\n",
       "          481,  468,  454,  437,  428,  409,  395,  373,  360,  352,  337,\n",
       "          316,  301,  286,  269,  260,  245,  234,  214,  201,  187,  173,\n",
       "          154,  130,  117,   89,   70,   55,   45,   27,   12,    6,    1,\n",
       "            0,    0]),\n",
       "  'TN': array([   0, 4083, 4827, 5137, 5336, 5467, 5563, 5645, 5741, 5827, 5886,\n",
       "         5936, 5980, 6025, 6063, 6098, 6138, 6168, 6212, 6247, 6270, 6297,\n",
       "         6316, 6339, 6364, 6383, 6406, 6425, 6440, 6453, 6468, 6484, 6504,\n",
       "         6516, 6532, 6544, 6556, 6571, 6580, 6593, 6607, 6617, 6629, 6635,\n",
       "         6650, 6663, 6672, 6691, 6700, 6716, 6721, 6736, 6746, 6759, 6764,\n",
       "         6778, 6793, 6807, 6819, 6831, 6844, 6857, 6874, 6890, 6905, 6921,\n",
       "         6939, 6952, 6966, 6983, 6992, 7011, 7025, 7047, 7060, 7068, 7083,\n",
       "         7104, 7119, 7134, 7151, 7160, 7175, 7186, 7206, 7219, 7233, 7247,\n",
       "         7266, 7290, 7303, 7331, 7350, 7365, 7375, 7393, 7408, 7414, 7419,\n",
       "         7420, 7420]),\n",
       "  'FN': array([  0,   2,   4,   6,   8,   8,   9,  11,  13,  15,  16,  17,  19,\n",
       "          24,  24,  25,  27,  28,  33,  37,  38,  38,  38,  41,  46,  47,\n",
       "          51,  53,  55,  56,  58,  61,  62,  64,  67,  67,  67,  70,  70,\n",
       "          70,  72,  76,  76,  78,  78,  80,  80,  81,  83,  83,  84,  88,\n",
       "          90,  92,  94,  98, 101, 104, 107, 110, 113, 117, 121, 122, 124,\n",
       "         125, 128, 134, 138, 147, 154, 158, 161, 167, 175, 182, 187, 196,\n",
       "         208, 221, 226, 231, 239, 247, 266, 288, 305, 325, 341, 358, 388,\n",
       "         407, 431, 455, 484, 515, 538, 557, 579, 580, 580])}}"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_eval.confusion_data_by_threshold_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "f657a4da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.13498077, 0.20146905, 0.24140821, 0.26831545, 0.2895996 ,\n",
       "       0.30756887, 0.32067039, 0.33131313, 0.34208955, 0.35041424,\n",
       "       0.35732165, 0.36602564, 0.37109375, 0.37735849, 0.38175109,\n",
       "       0.38784568, 0.39320388, 0.39887443, 0.40528949, 0.40923854,\n",
       "       0.41262849, 0.41592262, 0.42256721, 0.42530488, 0.43072173,\n",
       "       0.43474873, 0.43944773, 0.44222311, 0.44606061, 0.45134914,\n",
       "       0.4553719 , 0.45795171, 0.46335299, 0.46578836, 0.46861565,\n",
       "       0.47206583, 0.47552448, 0.47971781, 0.48460509, 0.48826715,\n",
       "       0.4929385 , 0.49655172, 0.49976863, 0.50326797, 0.50587682,\n",
       "       0.51142857, 0.51491819, 0.51672322, 0.51754386, 0.51939126,\n",
       "       0.52126607, 0.5224327 , 0.52668681, 0.52893401, 0.53251408,\n",
       "       0.5374677 , 0.53978159, 0.54019968, 0.54458599, 0.54681648,\n",
       "       0.54940282, 0.55232877, 0.55389718, 0.55432373, 0.55973079,\n",
       "       0.56203966, 0.56422018, 0.5669383 , 0.56858148, 0.57210682,\n",
       "       0.57606735, 0.57923497, 0.57706535, 0.58068536, 0.58259773,\n",
       "       0.58913738, 0.59158576, 0.58885246, 0.59121172, 0.58751696,\n",
       "       0.58677686, 0.59508772, 0.58957887, 0.58866279, 0.58849558,\n",
       "       0.58276125, 0.57791699, 0.57763475, 0.5764411 , 0.56896552,\n",
       "       0.5520362 , 0.53207547, 0.50446872, 0.46203209, 0.40941176,\n",
       "       0.30870712, 0.22157434, 0.11538462, 0.03722504, 0.00688468,\n",
       "       0.        ])"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fold1_dict=model_eval.confusion_data_by_threshold_[\"Fold 1\"]\n",
    "fold1_f1_by_threshold=(2*fold1_dict[\"TP\"])/((2*fold1_dict[\"TP\"])+fold1_dict[\"FP\"]+fold1_dict[\"FN\"])\n",
    "fold1_f1_by_threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "d22f347a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(0.5212660731948566)"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fold1_f1_by_threshold[50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "6d97f501",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5212660731948566"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_eval.fitted_dict_[\"Fold 1\"][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "fa19d179",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The dictionary has key being the fold identifier, and innder dictionary value for each key.\n",
      "In the inner dictionary, for each key (identifying TP, FP, TN, and FN), values are the count of the corresponding category, ordered according to the threshold being from >=0 to >=1 with step 0.01.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_eval.confusion_data_by_threshold_explain()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a717f68",
   "metadata": {},
   "source": [
    "## We now do it only for the personal data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dd223ba4",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_base=XGBClassifier(\n",
    "    device=\"cuda\", \n",
    "    tree_method=\"hist\", \n",
    "    eval_metric=\"aucpr\",\n",
    "    random_state=seed\n",
    ")\n",
    "\n",
    "pipe= Pipeline(\n",
    "    [\n",
    "        (\"data_transform\", data_processing.data_transform(per1=True, per2=True, cam1=False, cam2=False)), \n",
    "        (\"data_select\", data_processing.data_selector(cut=0.98, how=\"mi score\", mi_n_jobs=1)), \n",
    "        (\"RFE\", RFE(estimator=xgb_base, step=0.1)), \n",
    "        (\"XGB\", XGBClassifier(\n",
    "            device=\"cuda\", \n",
    "            tree_method=\"hist\", \n",
    "            eval_metric=\"aucpr\", \n",
    "            random_state=seed\n",
    "        ))\n",
    "    ]\n",
    ")\n",
    "\n",
    "param_dict={\n",
    "    \"XGB__max_depth\": [3, 4, 5, 6],\n",
    "    \"XGB__min_child_weight\": [1, 2, 4, 6],\n",
    "    \"XGB__subsample\": np.linspace(0.7, 1.0, 4),\n",
    "    \"XGB__colsample_bytree\": np.linspace(0.7, 1.0, 4),\n",
    "    \"XGB__learning_rate\": np.geomspace(1e-2, 0.2, 5),\n",
    "    \"XGB__n_estimators\": [600, 1000, 1400],  \n",
    "    \"XGB__reg_lambda\": np.geomspace(1e-2, 100, 6),\n",
    "    \"XGB__reg_alpha\": np.geomspace(1e-3, 10, 6),\n",
    "    \"XGB__gamma\": np.linspace(0.0, 5.0, 6),\n",
    "    \"XGB__scale_pos_weight\": None # The model_eval will set this \n",
    "}\n",
    "\n",
    "SKF=StratifiedKFold(n_splits=5, shuffle=True, random_state=seed)\n",
    "outer_split=list(SKF.split(X=df_feat, y=df_tar))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e32c4015",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_eval_per=training.model_eval(search_method=\"Random\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dff1e72",
   "metadata": {},
   "source": [
    "This takes 50 mins without gpu. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a64957d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_eval_per.eval(df_feat=df_feat, df_tar=df_tar, pipe=pipe, outer_cv=outer_split, param_dict=param_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "25f16dd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitted dictionary saved\n"
     ]
    }
   ],
   "source": [
    "model_eval_per.save_dict(\"../data/fitted/xgboost/fitted_dict_per_run_1.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "21248a99",
   "metadata": {},
   "outputs": [],
   "source": [
    "fitted_dict_per=model_eval_per.fitted_dict_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bc6082da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Fold 1': (Pipeline(steps=[('data_transform', data_transform(cam1=False, cam2=False)),\n",
       "                  ('data_select',\n",
       "                   data_selector(cut=0.98, how='mi score', mi_n_jobs=1)),\n",
       "                  ('RFE',\n",
       "                   RFE(estimator=XGBClassifier(base_score=None, booster=None,\n",
       "                                               callbacks=None,\n",
       "                                               colsample_bylevel=None,\n",
       "                                               colsample_bynode=None,\n",
       "                                               colsample_bytree=None,\n",
       "                                               device='cuda',\n",
       "                                               early_stopping_rounds=None,\n",
       "                                               enable_categorical=False...\n",
       "                                 gamma=np.float64(1.0), grow_policy=None,\n",
       "                                 importance_type=None,\n",
       "                                 interaction_constraints=None,\n",
       "                                 learning_rate=np.float64(0.01), max_bin=None,\n",
       "                                 max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "                                 max_delta_step=None, max_depth=4,\n",
       "                                 max_leaves=None, min_child_weight=1, missing=nan,\n",
       "                                 monotone_constraints=None, multi_strategy=None,\n",
       "                                 n_estimators=600, n_jobs=None,\n",
       "                                 num_parallel_tree=None, ...))]),\n",
       "  0.15995567048393056,\n",
       "  0.6323084445741546,\n",
       "  0.1426894458702212,\n",
       "  array([0.4046179 , 0.5064531 , 0.53957605, ..., 0.5878314 , 0.6251945 ,\n",
       "         0.54949796], dtype=float32)),\n",
       " 'Fold 2': (Pipeline(steps=[('data_transform', data_transform(cam1=False, cam2=False)),\n",
       "                  ('data_select',\n",
       "                   data_selector(cut=0.98, how='mi score', mi_n_jobs=1)),\n",
       "                  ('RFE',\n",
       "                   RFE(estimator=XGBClassifier(base_score=None, booster=None,\n",
       "                                               callbacks=None,\n",
       "                                               colsample_bylevel=None,\n",
       "                                               colsample_bynode=None,\n",
       "                                               colsample_bytree=None,\n",
       "                                               device='cuda',\n",
       "                                               early_stopping_rounds=None,\n",
       "                                               enable_categorical=False...\n",
       "                                 gamma=np.float64(1.0), grow_policy=None,\n",
       "                                 importance_type=None,\n",
       "                                 interaction_constraints=None,\n",
       "                                 learning_rate=np.float64(0.01), max_bin=None,\n",
       "                                 max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "                                 max_delta_step=None, max_depth=3,\n",
       "                                 max_leaves=None, min_child_weight=2, missing=nan,\n",
       "                                 monotone_constraints=None, multi_strategy=None,\n",
       "                                 n_estimators=600, n_jobs=None,\n",
       "                                 num_parallel_tree=None, ...))]),\n",
       "  0.17861339600470036,\n",
       "  0.6367945002267987,\n",
       "  0.13308684242032806,\n",
       "  array([0.43816584, 0.5328313 , 0.34302068, ..., 0.6125923 , 0.4637006 ,\n",
       "         0.46991423], dtype=float32)),\n",
       " 'Fold 3': (Pipeline(steps=[('data_transform', data_transform(cam1=False, cam2=False)),\n",
       "                  ('data_select',\n",
       "                   data_selector(cut=0.98, how='mi score', mi_n_jobs=1)),\n",
       "                  ('RFE',\n",
       "                   RFE(estimator=XGBClassifier(base_score=None, booster=None,\n",
       "                                               callbacks=None,\n",
       "                                               colsample_bylevel=None,\n",
       "                                               colsample_bynode=None,\n",
       "                                               colsample_bytree=None,\n",
       "                                               device='cuda',\n",
       "                                               early_stopping_rounds=None,\n",
       "                                               enable_categorical=False...\n",
       "                                 gamma=np.float64(1.0), grow_policy=None,\n",
       "                                 importance_type=None,\n",
       "                                 interaction_constraints=None,\n",
       "                                 learning_rate=np.float64(0.01), max_bin=None,\n",
       "                                 max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "                                 max_delta_step=None, max_depth=3,\n",
       "                                 max_leaves=None, min_child_weight=2, missing=nan,\n",
       "                                 monotone_constraints=None, multi_strategy=None,\n",
       "                                 n_estimators=600, n_jobs=None,\n",
       "                                 num_parallel_tree=None, ...))]),\n",
       "  0.15406726070709975,\n",
       "  0.5876092887685811,\n",
       "  0.12478629715448447,\n",
       "  array([0.5549331 , 0.3294987 , 0.3255453 , ..., 0.36357144, 0.7913194 ,\n",
       "         0.6054733 ], dtype=float32)),\n",
       " 'Fold 4': (Pipeline(steps=[('data_transform', data_transform(cam1=False, cam2=False)),\n",
       "                  ('data_select',\n",
       "                   data_selector(cut=0.98, how='mi score', mi_n_jobs=1)),\n",
       "                  ('RFE',\n",
       "                   RFE(estimator=XGBClassifier(base_score=None, booster=None,\n",
       "                                               callbacks=None,\n",
       "                                               colsample_bylevel=None,\n",
       "                                               colsample_bynode=None,\n",
       "                                               colsample_bytree=None,\n",
       "                                               device='cuda',\n",
       "                                               early_stopping_rounds=None,\n",
       "                                               enable_categorical=False...\n",
       "                                 gamma=np.float64(5.0), grow_policy=None,\n",
       "                                 importance_type=None,\n",
       "                                 interaction_constraints=None,\n",
       "                                 learning_rate=np.float64(0.01), max_bin=None,\n",
       "                                 max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "                                 max_delta_step=None, max_depth=3,\n",
       "                                 max_leaves=None, min_child_weight=4, missing=nan,\n",
       "                                 monotone_constraints=None, multi_strategy=None,\n",
       "                                 n_estimators=1400, n_jobs=None,\n",
       "                                 num_parallel_tree=None, ...))]),\n",
       "  0.18256772673733804,\n",
       "  0.603810104313507,\n",
       "  0.1317111005376985,\n",
       "  array([0.2683918 , 0.46722987, 0.16925256, ..., 0.33496052, 0.6536984 ,\n",
       "         0.38692495], dtype=float32)),\n",
       " 'Fold 5': (Pipeline(steps=[('data_transform', data_transform(cam1=False, cam2=False)),\n",
       "                  ('data_select',\n",
       "                   data_selector(cut=0.98, how='mi score', mi_n_jobs=1)),\n",
       "                  ('RFE',\n",
       "                   RFE(estimator=XGBClassifier(base_score=None, booster=None,\n",
       "                                               callbacks=None,\n",
       "                                               colsample_bylevel=None,\n",
       "                                               colsample_bynode=None,\n",
       "                                               colsample_bytree=None,\n",
       "                                               device='cuda',\n",
       "                                               early_stopping_rounds=None,\n",
       "                                               enable_categorical=False...\n",
       "                                 gamma=np.float64(0.0), grow_policy=None,\n",
       "                                 importance_type=None,\n",
       "                                 interaction_constraints=None,\n",
       "                                 learning_rate=np.float64(0.01), max_bin=None,\n",
       "                                 max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "                                 max_delta_step=None, max_depth=3,\n",
       "                                 max_leaves=None, min_child_weight=1, missing=nan,\n",
       "                                 monotone_constraints=None, multi_strategy=None,\n",
       "                                 n_estimators=1000, n_jobs=None,\n",
       "                                 num_parallel_tree=None, ...))]),\n",
       "  0.19885714285714284,\n",
       "  0.6253125290454503,\n",
       "  0.1494364709833783,\n",
       "  array([0.30245095, 0.2666078 , 0.38288853, ..., 0.5293014 , 0.5745098 ,\n",
       "         0.44123703], dtype=float32))}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fitted_dict_per"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deep_learning_3_11_8",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
